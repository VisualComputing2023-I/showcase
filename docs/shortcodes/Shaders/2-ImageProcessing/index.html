<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="2 - Image And Video Processing # Exercise Implement an image / video processing app supporting different masks, including other kernel sizes different than 3x3, and:
A region-of-interest base tool to selectively apply a given mask.Hint: circular regions around the mouse pointer are handy and quite simple to implement by means of glsl distance. A magnifier tool. Requires a bit of research. For instance, look for it in shadertoy. Integrate luma and other coloring brightness tools."><meta name=theme-color content="#FFFFFF"><meta name=color-scheme content="light dark"><meta property="og:title" content><meta property="og:description" content="2 - Image And Video Processing # Exercise Implement an image / video processing app supporting different masks, including other kernel sizes different than 3x3, and:
A region-of-interest base tool to selectively apply a given mask.Hint: circular regions around the mouse pointer are handy and quite simple to implement by means of glsl distance. A magnifier tool. Requires a bit of research. For instance, look for it in shadertoy. Integrate luma and other coloring brightness tools."><meta property="og:type" content="article"><meta property="og:url" content="https://visualcomputing2023-i.github.io/showcase/docs/shortcodes/Shaders/2-ImageProcessing/"><meta property="article:section" content="docs"><meta property="article:modified_time" content="2023-05-25T10:41:38-05:00"><title>2 Image Processing | Visual Computing 2023 I</title><link rel=manifest href=/showcase/manifest.json><link rel=icon href=/showcase/favicon.png type=image/x-icon><link rel=stylesheet href=/showcase/book.min.4b35fed0bea034bbc19c89c71e14b73fb9c68cfcc586b9382adfb9b7b103ba06.css integrity="sha256-SzX+0L6gNLvBnInHHhS3P7nGjPzFhrk4Kt+5t7EDugY=" crossorigin=anonymous><script defer src=/showcase/flexsearch.min.js></script>
<script defer src=/showcase/en.search.min.3a8d658c77eb93c7f12a2b8af49a700131e474f288eefb605d9fa61576dbe5a7.js integrity="sha256-Oo1ljHfrk8fxKiuK9JpwATHkdPKI7vtgXZ+mFXbb5ac=" crossorigin=anonymous></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/showcase/><span>Visual Computing 2023 I</span></a></h2><div class=book-search><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><ul><li class=book-section-flat><span>Shortcodes</span><ul><li><input type=checkbox id=section-ec67a64aba70b9df3d2a9acd6c92e3bc class=toggle>
<label for=section-ec67a64aba70b9df3d2a9acd6c92e3bc class="flex justify-between"><a href=/showcase/docs/shortcodes/p5/>P5</a></label><ul><li><a href=/showcase/docs/shortcodes/p5/iframe/>Iframe</a></li><li><a href=/showcase/docs/shortcodes/p5/div/>Div</a></li></ul></li><li><input type=checkbox id=section-37d133451a87125afc7e4d4a60cdb12b class=toggle checked>
<label for=section-37d133451a87125afc7e4d4a60cdb12b class="flex justify-between"><a href=/showcase/docs/shortcodes/Shaders/>Shaders</a></label><ul><li><a href=/showcase/docs/shortcodes/Shaders/1-ProceduralTexturing/>1 Procedural Texturing</a></li><li><a href=/showcase/docs/shortcodes/Shaders/2-ImageProcessing/ class=active>2 Image Processing</a></li><li><a href=/showcase/docs/shortcodes/Shaders/3-Texturing/>3 Texturing</a></li></ul></li><li><input type=checkbox id=section-46ef92ed4553b248f8f108332fae886a class=toggle>
<label for=section-46ef92ed4553b248f8f108332fae886a class="flex justify-between"><a href=/showcase/docs/shortcodes/Team/>Team</a></label><ul><li><a href=/showcase/docs/shortcodes/Team/Diego-Alvarado/>Diego Alvarado</a></li><li><a href=/showcase/docs/shortcodes/Team/Juli%C3%A1n-Manosalva/>Julián Manosalva</a></li><li><a href=/showcase/docs/shortcodes/Team/Sebasti%C3%A1n-Pach%C3%B3n/>Sebastián Pachón</a></li></ul></li><li><input type=checkbox id=section-94839c8d59cd3fd9e827edbeb4e69371 class=toggle>
<label for=section-94839c8d59cd3fd9e827edbeb4e69371 class="flex justify-between"><a href=/showcase/docs/shortcodes/VisualIllutions/>Visual Illutions</a></label><ul><li><a href=/showcase/docs/shortcodes/VisualIllutions/1-Visual-Illutions/>1 Visual Illutions</a></li><li><a href=/showcase/docs/shortcodes/VisualIllutions/2-Masking/>2 Masking</a></li><li><a href=/showcase/docs/shortcodes/VisualIllutions/3-Mach-Bands/>3 Mach Bands</a></li></ul></li></ul></li></ul><ul><li><a href=/showcase/posts/>Blog</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/showcase/svg/menu.svg class=book-icon alt=Menu></label>
<strong>2 Image Processing</strong>
<label for=toc-control><img src=/showcase/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#2---image-and-video-processing>2 - Image And Video Processing</a></li><li><a href=#introducción><strong>Introducción</strong></a><ul><li><ul><li><a href=#solución-código>Solución (Código):</a></li><li><a href=#resultado>Resultado:</a></li></ul></li></ul></li><li><a href=#conclusiones><strong>Conclusiones</strong></a></li><li><a href=#trabajo-futuro><strong>Trabajo futuro</strong></a></li><li><a href=#referencias>Referencias</a></li></ul></nav></aside></header><article class=markdown><h1 id=2---image-and-video-processing>2 - Image And Video Processing
<a class=anchor href=#2---image-and-video-processing>#</a></h1><blockquote class="book-hint info"><p><b>Exercise</b></p><p>Implement an image / video processing app supporting different masks, including other kernel sizes different than 3x3, and:</p><ul><li>A region-of-interest base tool to selectively apply a given mask.Hint: circular regions around the mouse pointer are handy and quite simple to implement by means of glsl distance.</li><li>A magnifier tool. Requires a bit of research. For instance, look for it in shadertoy.</li><li>Integrate luma and other coloring brightness tools.</li></ul></blockquote><h1 id=introducción><strong>Introducción</strong>
<a class=anchor href=#introducci%c3%b3n>#</a></h1><p>El análisis y procesamiento de imágenes se realiza a través de computadoras, debido a la complejidad y el número de cálculos necesarios para realizarlo. Es por esto que, si bien la formulación matemática necesaria para su realización data de varios siglos atrás, la posibilidad real de utilizarla de forma cotidiana en la práctica clínica ha sido posible recién en las últimas décadas, gracias al avance en las tecnologías del hardware.</p><p>La proliferación de nuevos equipamientos con capacidad para realizar millones de operaciones por segundo y su extensión a la vida cotidiana y a todo tipo de usuario, ha hecho posible que el análisis y procesamiento de imágenes digitales se constituya en un gran campo de estudio. En la actualidad, esta tecnología se encuentra incorporada incluso en todo tipo de equipamiento doméstico, como cámaras digitales, scaners y teléfonos celulares, entre otros.</p><p>En términos históricos, la utilización de imágenes radiográficas para diagnóstico clínico data prácticamente desde el descubrimiento de los rayos X en 1895 (Röentgen). Incluso, las imágenes funcionales a partir de la emisión de fotones (rayos γ
) por parte de radionucleidos ya cuenta con más de 90 años de antigüedad (Heavesy & Seaborg, 1924). Sin embargo, las imágenes eran adquiridas sobre films radiográficos o directamente in vivo, por lo que su correcto procesamiento no ha explotado su real potencialidad sino hasta la incorporación de la tecnología que permitió digitalizarlas.</p><p>El motivo principal de esta “aparición tardía” del procesamiento de imágenes ha sido entonces, debido a los requerimientos de hardware tanto para el procesamiento de las mismas como para la representación de estas en sistemas gráficos de alta performance. Paralelamente a este desarrollo, la formulación de algoritmos para el procesamiento ha seguido los avances tecnológicos logrando un alto grado de sofisticación y manipulación de imágenes en tiempo casi real.</p><p>La variedad actual de técnicas, algoritmos y desarrollos de software y hardware utilizados en el procesamiento de imágenes digitales escapa al alcance de cualquier curso. En ellos se aprovechan técnicas desarrolladas inicialmente sobre conceptos fundacionales para el análisis de imágenes, y se incorporan conceptos y nociones de los más variados, propios de la física y la matemática, como el caso de la entropía o la métrica.</p><h3 id=solución-código>Solución (Código):
<a class=anchor href=#soluci%c3%b3n-c%c3%b3digo>#</a></h3><p>A continuación se presentan los extractos más significativos del código utilizado en el fragment shader.</p><p>Variables utilizadas:</p><details><summary>Variables</summary><div class=markdown-inner><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-glsl data-lang=glsl><span style=display:flex><span><span style=color:#66d9ef>precision</span> <span style=color:#66d9ef>mediump</span> <span style=color:#66d9ef>float</span>;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>uniform</span> <span style=color:#66d9ef>sampler2D</span> texture;
</span></span><span style=display:flex><span><span style=color:#66d9ef>uniform</span> <span style=color:#66d9ef>vec2</span> texOffset;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// Herramienta de brillo seleccionada</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>uniform</span> <span style=color:#66d9ef>int</span> brightnessTool;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// Posicion del mouse</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>uniform</span> <span style=color:#66d9ef>vec2</span> mouse;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// Resolucion de la pantalla</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>uniform</span> <span style=color:#66d9ef>vec2</span> resolution;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>uniform</span> <span style=color:#66d9ef>float</span> kernel[<span style=color:#ae81ff>9</span>];
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>uniform</span> <span style=color:#66d9ef>bool</span> magnifier;
</span></span><span style=display:flex><span><span style=color:#66d9ef>uniform</span> <span style=color:#66d9ef>bool</span> region;
</span></span><span style=display:flex><span><span style=color:#66d9ef>uniform</span> <span style=color:#66d9ef>float</span> radius;
</span></span><span style=display:flex><span><span style=color:#66d9ef>uniform</span> <span style=color:#66d9ef>float</span> scale;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>varying</span> <span style=color:#66d9ef>vec2</span> texcoords2;
</span></span></code></pre></div></div></details><p>Función que aplica y determina el kernel seleccionado:</p><details><summary>Aplicar kernel</summary><div class=markdown-inner><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-glsl data-lang=glsl><span style=display:flex><span><span style=color:#66d9ef>vec4</span> applyKernel(){
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>vec2</span> tc0 <span style=color:#f92672>=</span> texcoords2 <span style=color:#f92672>+</span> <span style=color:#66d9ef>vec2</span>(<span style=color:#f92672>-</span>texOffset.s, <span style=color:#f92672>-</span>texOffset.t);
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>vec2</span> tc1 <span style=color:#f92672>=</span> texcoords2 <span style=color:#f92672>+</span> <span style=color:#66d9ef>vec2</span>(         <span style=color:#ae81ff>0.0</span>, <span style=color:#f92672>-</span>texOffset.t);
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>vec2</span> tc2 <span style=color:#f92672>=</span> texcoords2 <span style=color:#f92672>+</span> <span style=color:#66d9ef>vec2</span>(<span style=color:#f92672>+</span>texOffset.s, <span style=color:#f92672>-</span>texOffset.t);
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>vec2</span> tc3 <span style=color:#f92672>=</span> texcoords2 <span style=color:#f92672>+</span> <span style=color:#66d9ef>vec2</span>(<span style=color:#f92672>-</span>texOffset.s,          <span style=color:#ae81ff>0.0</span>);
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>vec2</span> tc4 <span style=color:#f92672>=</span> texcoords2 <span style=color:#f92672>+</span> <span style=color:#66d9ef>vec2</span>(         <span style=color:#ae81ff>0.0</span>,          <span style=color:#ae81ff>0.0</span>);
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>vec2</span> tc5 <span style=color:#f92672>=</span> texcoords2 <span style=color:#f92672>+</span> <span style=color:#66d9ef>vec2</span>(<span style=color:#f92672>+</span>texOffset.s,          <span style=color:#ae81ff>0.0</span>);
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>vec2</span> tc6 <span style=color:#f92672>=</span> texcoords2 <span style=color:#f92672>+</span> <span style=color:#66d9ef>vec2</span>(<span style=color:#f92672>-</span>texOffset.s, <span style=color:#f92672>+</span>texOffset.t);
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>vec2</span> tc7 <span style=color:#f92672>=</span> texcoords2 <span style=color:#f92672>+</span> <span style=color:#66d9ef>vec2</span>(         <span style=color:#ae81ff>0.0</span>, <span style=color:#f92672>+</span>texOffset.t);
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>vec2</span> tc8 <span style=color:#f92672>=</span> texcoords2 <span style=color:#f92672>+</span> <span style=color:#66d9ef>vec2</span>(<span style=color:#f92672>+</span>texOffset.s, <span style=color:#f92672>+</span>texOffset.t);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>vec4</span> rgba[<span style=color:#ae81ff>9</span>];
</span></span><span style=display:flex><span>  rgba[<span style=color:#ae81ff>0</span>] <span style=color:#f92672>=</span> texture2D(texture, tc0);
</span></span><span style=display:flex><span>  rgba[<span style=color:#ae81ff>1</span>] <span style=color:#f92672>=</span> texture2D(texture, tc1);
</span></span><span style=display:flex><span>  rgba[<span style=color:#ae81ff>2</span>] <span style=color:#f92672>=</span> texture2D(texture, tc2);
</span></span><span style=display:flex><span>  rgba[<span style=color:#ae81ff>3</span>] <span style=color:#f92672>=</span> texture2D(texture, tc3);
</span></span><span style=display:flex><span>  rgba[<span style=color:#ae81ff>4</span>] <span style=color:#f92672>=</span> texture2D(texture, tc4);
</span></span><span style=display:flex><span>  rgba[<span style=color:#ae81ff>5</span>] <span style=color:#f92672>=</span> texture2D(texture, tc5);
</span></span><span style=display:flex><span>  rgba[<span style=color:#ae81ff>6</span>] <span style=color:#f92672>=</span> texture2D(texture, tc6);
</span></span><span style=display:flex><span>  rgba[<span style=color:#ae81ff>7</span>] <span style=color:#f92672>=</span> texture2D(texture, tc7);
</span></span><span style=display:flex><span>  rgba[<span style=color:#ae81ff>8</span>] <span style=color:#f92672>=</span> texture2D(texture, tc8);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>vec4</span> convolution;
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>for</span> (<span style=color:#66d9ef>int</span> i <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; i <span style=color:#f92672>&lt;</span> <span style=color:#ae81ff>9</span>; i<span style=color:#f92672>++</span>) {
</span></span><span style=display:flex><span>    convolution <span style=color:#f92672>+=</span> rgba[i]<span style=color:#f92672>*</span>kernel[i];
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  convolution <span style=color:#f92672>=</span> <span style=color:#66d9ef>vec4</span>(convolution.rgb, <span style=color:#ae81ff>1.0</span>);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>return</span> convolution;
</span></span><span style=display:flex><span>}
</span></span></code></pre></div></div></details><p>Función empleada para calcular la lupa o el área de interés:</p><details><summary>Área de interés</summary><div class=markdown-inner><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-glsl data-lang=glsl><span style=display:flex><span><span style=color:#66d9ef>float</span> dist <span style=color:#f92672>=</span> distance(gl_FragCoord.xy, mouse);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>if</span>(dist <span style=color:#f92672>&lt;</span> radius){
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>}
</span></span></code></pre></div></div></details><p>Fucnione para aplicar el efecto de lupa:</p><details><summary>Efecto de lupa</summary><div class=markdown-inner><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-glsl data-lang=glsl><span style=display:flex><span><span style=color:#66d9ef>vec2</span> mouseDist <span style=color:#f92672>=</span> gl_FragCoord.xy <span style=color:#f92672>-</span> mouse;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>vec2</span> newCoords <span style=color:#f92672>=</span> gl_FragCoord.xy;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>vec2</span> zoomed <span style=color:#f92672>=</span> (newCoords <span style=color:#f92672>-</span> (mouseDist <span style=color:#f92672>*</span> scale)) <span style=color:#f92672>/</span> resolution;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// Se invierte el eje y</span>
</span></span><span style=display:flex><span>zoomed <span style=color:#f92672>=</span> <span style=color:#66d9ef>vec2</span>(zoomed.x, <span style=color:#ae81ff>1.0</span> <span style=color:#f92672>-</span> zoomed.y);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>vec4</span> zoomedTexel <span style=color:#f92672>=</span> texture2D(texture, zoomed);
</span></span><span style=display:flex><span>zoomedTexel <span style=color:#f92672>=</span> changeBrightness(zoomedTexel);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>gl_FragColor <span style=color:#f92672>=</span> zoomedTexel;
</span></span></code></pre></div></div></details><br><h3 id=resultado>Resultado:
<a class=anchor href=#resultado>#</a></h3><div style=display:flex;flex-direction:column;align-items:center;justify-content:center id=cbat><iframe id=sketch style=width:705px;height:850px srcdoc="
        <!DOCTYPE html>
        <html>
          <head>
            <script src=https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.5.0/p5.min.js></script>
            <script src=https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.5.0/addons/p5.sound.min.js></script>
             <script src=https://cdn.jsdelivr.net/gh/VisualComputing/p5.treegl/p5.treegl.js></script> 
             <script src=https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.4.2/p5.min.js></script> 
            
            
            
            <script src=/showcase/sketches/image_processing/sketch.js></script>
          </head>
          <body>
          </body>
        </html>
      "></iframe></div><h1 id=conclusiones><strong>Conclusiones</strong>
<a class=anchor href=#conclusiones>#</a></h1><ol><li><p>En la computación visual, el procesamiento de imágenes desempeña un papel fundamental al permitir la extracción de información valiosa a partir de datos visuales, lo que impulsa el avance de diversas aplicaciones en campos como la medicina, la robótica y la realidad virtual.</p></li><li><p>El continuo desarrollo de algoritmos de procesamiento de imágenes en la computación visual ha llevado a mejoras significativas en áreas como el reconocimiento facial, la detección de objetos y la segmentación de imágenes, lo que ha ampliado las posibilidades de aplicaciones prácticas y creativas.</p></li><li><p>El procesamiento de imágenes en tiempo real se ha convertido en una necesidad cada vez más apremiante en aplicaciones como la realidad aumentada y los sistemas de visión en tiempo real, lo que requiere algoritmos eficientes y técnicas optimizadas para ofrecer resultados instantáneos y precisos.</p></li><li><p>La evolución de la inteligencia artificial y el aprendizaje automático ha impulsado enormemente el procesamiento de imágenes en la computación visual, permitiendo tareas más complejas como el reconocimiento de patrones, la generación de imágenes y la interpretación semántica de contenido visual.</p></li><li><p>A medida que el procesamiento de imágenes en la computación visual avanza, también surgen desafíos éticos y de privacidad, como la manipulación de imágenes, la privacidad de datos y la responsabilidad en el uso de información visual. Es fundamental abordar estos desafíos de manera responsable para garantizar el beneficio y la protección de los usuarios y la sociedad en general.</p></li></ol><h1 id=trabajo-futuro><strong>Trabajo futuro</strong>
<a class=anchor href=#trabajo-futuro>#</a></h1><p>El procesamiento de imágenes en la computación visual es un campo en continuo progreso y se espera que siga ofreciendo nuevas oportunidades y desafíos en el futuro.</p><p>En primer lugar, se anticipa una mayor atención hacia la inteligencia artificial y el aprendizaje automático con el fin de mejorar la precisión y eficiencia del procesamiento de imágenes. Los algoritmos de detección, reconocimiento y seguimiento de objetos se beneficiarán de modelos más avanzados y técnicas de entrenamiento sofisticadas.</p><p>Además, se prevé un mayor enfoque en el procesamiento de imágenes en tiempo real, especialmente en aplicaciones de realidad aumentada y virtual. Esto requerirá algoritmos y técnicas más rápidos y eficientes que ofrezcan resultados en tiempo real sin comprometer la calidad de la imagen.</p><p>Otro aspecto relevante es el procesamiento de imágenes en dispositivos móviles y en entornos con restricciones de energía. A medida que los dispositivos móviles se vuelven más potentes, resultará crucial desarrollar algoritmos optimizados y técnicas de procesamiento de imágenes que se adapten a las limitaciones de recursos y energía.</p><p>La colaboración entre la computación visual y otras disciplinas, como la robótica y la medicina, también experimentará un crecimiento significativo. El procesamiento de imágenes desempeñará un papel fundamental en el desarrollo de sistemas autónomos, como robots y vehículos autónomos, así como en aplicaciones médicas como el diagnóstico por imagen y la cirugía asistida por ordenador.</p><p>Por último, el procesamiento de imágenes deberá enfrentar desafíos éticos y de privacidad en el futuro. A medida que la tecnología avanza, será necesario abordar cuestiones relacionadas con la manipulación de imágenes, la protección de datos personales y el uso responsable de la información visual.</p><p>En resumen, el futuro del procesamiento de imágenes en la computación visual promete avances emocionantes en áreas como la inteligencia artificial, la realidad aumentada, la eficiencia energética y la colaboración interdisciplinaria. Al explorar estas áreas, resulta fundamental abordar los desafíos éticos y de privacidad para garantizar un desarrollo responsable y beneficioso de esta tecnología en constante evolución.</p><h1 id=referencias>Referencias
<a class=anchor href=#referencias>#</a></h1><ul><li><p><a href=https://www.famaf.unc.edu.ar/~pperez1/manuales/cim/cap2.html>Información de consulta (Introducción)</a></p></li><li><p><a href=https://www.vistronica.com/blog/post/procesamiento-de-imagenes.html>Procesamiento de imágenes</a></p></li><li><p><a href=https://codepen.io/tag/p5-js>Primera guía para la implementación de los ejercicios</a></p></li><li><p><a href=https://github.com/CodingTrain/website-archive/tree/main/CodingChallenges>Segunda guía para la implementación de los ejercicios</a></p></li><li><p><a href=https://openprocessing.org/>Tercera guía para la implementación de los ejercicios</a></p></li><li><p><a href=https://chat.openai.com/>Edición de texto</a></p></li></ul><style>#cbat{background-color:#fff;opacity:1;background-image:radial-gradient(#444cf7 .5px,white .5px);background-size:10px 10px;border-radius:1rem;padding:1rem}#cbat iframe{border:none}</style></article><footer class=book-footer><div class="flex flex-wrap justify-between"><div><a class="flex align-center" href=https://jupachonc.github.io/showcase/commit/27e9ef4d32e78dd3cf107f00ba6d742c09c52d11 title='Last modified by Julian Manosalva Manrique | May 25, 2023' target=_blank rel=noopener><img src=/showcase/svg/calendar.svg class=book-icon alt=Calendar>
<span>May 25, 2023</span></a></div></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#2---image-and-video-processing>2 - Image And Video Processing</a></li><li><a href=#introducción><strong>Introducción</strong></a><ul><li><ul><li><a href=#solución-código>Solución (Código):</a></li><li><a href=#resultado>Resultado:</a></li></ul></li></ul></li><li><a href=#conclusiones><strong>Conclusiones</strong></a></li><li><a href=#trabajo-futuro><strong>Trabajo futuro</strong></a></li><li><a href=#referencias>Referencias</a></li></ul></nav></div></aside></main></body></html>